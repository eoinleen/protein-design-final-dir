{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "15mOaR42U5JpCzgUgyrzICxRtr8YVSMTi",
      "authorship_tag": "ABX9TyNpJh/pgT+UMB5+ukTGpWQC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eoinleen/protein-design-final-dir/blob/main/Extract_fasta_from_pdb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LgASdgakvBJG",
        "outputId": "45eccaab-5ef3-4e34-f209-b75ec9ae7a3e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounting Google Drive...\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "\n",
            "PDB Directory: /content/drive/MyDrive/Evolving_hits_using_ProteinMPNN/20250303-3NOBEK/0_top_binders\n",
            "Chain ID: A\n",
            "Do you want to change these settings? (yes/no): no\n",
            "\n",
            "Processing PDB files in /content/drive/MyDrive/Evolving_hits_using_ProteinMPNN/20250303-3NOBEK/0_top_binders, extracting chain A...\n",
            "Found 13 PDB files in /content/drive/MyDrive/Evolving_hits_using_ProteinMPNN/20250303-3NOBEK/0_top_binders\n",
            "Extracting sequences from chain A...\n",
            "Processed 1_bind_0_dldesign_9965_af2pred.pdb -> 1_9965.txt\n",
            "Processed 1_bind_0_dldesign_2056_af2pred.pdb -> 1_2056.txt\n",
            "Processed 1_bind_0_dldesign_5160_af2pred.pdb -> 1_5160.txt\n",
            "Processed 1_bind_0_dldesign_7384_af2pred.pdb -> 1_7384.txt\n",
            "Processed 1_bind_0_dldesign_2304_af2pred.pdb -> 1_2304.txt\n",
            "Processed 1_bind_0_dldesign_7578_af2pred.pdb -> 1_7578.txt\n",
            "Processed 1_bind_0_dldesign_8480_af2pred.pdb -> 1_8480.txt\n",
            "Processed 1_bind_0_dldesign_2777_af2pred.pdb -> 1_2777.txt\n",
            "Processed 1_bind_0_dldesign_1829_af2pred.pdb -> 1_1829.txt\n",
            "Processed 1_bind_0_dldesign_5024_af2pred.pdb -> 1_5024.txt\n",
            "Processed 1_bind_0_dldesign_2795_af2pred.pdb -> 1_2795.txt\n",
            "Processed 1_bind_0_dldesign_1708_af2pred.pdb -> 1_1708.txt\n",
            "Processed 1_bind_0design0_af2pred.pdb -> 1_.txt\n",
            "\n",
            "Created combined FASTA file: /content/drive/MyDrive/Evolving_hits_using_ProteinMPNN/20250303-3NOBEK/0_top_binders/all_sequences.txt\n",
            "\n",
            "Processed 13 PDB files.\n",
            "FASTA files have been saved to /content/drive/MyDrive/Evolving_hits_using_ProteinMPNN/20250303-3NOBEK/0_top_binders\n",
            "\n",
            "Process completed successfully!\n"
          ]
        }
      ],
      "source": [
        "# PDB to FASTA Converter for Google Colab\n",
        "# This notebook extracts amino acid sequences from PDB files and saves them in FASTA format\n",
        "\n",
        "# ===== SETTINGS - EDIT THESE =====\n",
        "# Directory containing your PDB files (edit this path)\n",
        "PDB_DIRECTORY = \"/content/drive/MyDrive/Evolving_hits_using_ProteinMPNN/20250303-3NOBEK/0_top_binders\"\n",
        "# Chain to extract (default is 'A')\n",
        "CHAIN_ID = \"A\"\n",
        "# ================================\n",
        "\n",
        "# Install required packages\n",
        "!pip install -q biopython\n",
        "\n",
        "# Import necessary libraries\n",
        "import os\n",
        "import re\n",
        "import glob\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "print(\"Mounting Google Drive...\")\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Dictionary to convert three-letter amino acid codes to one-letter codes\n",
        "three_to_one = {\n",
        "    'ALA': 'A', 'CYS': 'C', 'ASP': 'D', 'GLU': 'E',\n",
        "    'PHE': 'F', 'GLY': 'G', 'HIS': 'H', 'ILE': 'I',\n",
        "    'LYS': 'K', 'LEU': 'L', 'MET': 'M', 'ASN': 'N',\n",
        "    'PRO': 'P', 'GLN': 'Q', 'ARG': 'R', 'SER': 'S',\n",
        "    'THR': 'T', 'VAL': 'V', 'TRP': 'W', 'TYR': 'Y'\n",
        "}\n",
        "\n",
        "def extract_sequence_from_pdb(pdb_file, chain_id):\n",
        "    \"\"\"Extract the amino acid sequence from a specified chain in a PDB file.\"\"\"\n",
        "    sequence = \"\"\n",
        "    current_res_num = None\n",
        "\n",
        "    # Read the PDB file and extract the sequence\n",
        "    with open(pdb_file, 'r') as f:\n",
        "        for line in f:\n",
        "            if line.startswith('ATOM') and line[21] == chain_id:\n",
        "                # Extract residue information\n",
        "                res_name = line[17:20].strip()\n",
        "                res_num = int(line[22:26])\n",
        "\n",
        "                # Avoid duplicate residues (only add each residue once)\n",
        "                if res_num != current_res_num:\n",
        "                    if res_name in three_to_one:\n",
        "                        sequence += three_to_one[res_name]\n",
        "                    current_res_num = res_num\n",
        "\n",
        "    return sequence\n",
        "\n",
        "def parse_design_number(filename):\n",
        "    \"\"\"Parse the design number from the filename.\"\"\"\n",
        "    # Extract the first number before '_bind_'\n",
        "    match = re.search(r'(\\d+)_bind_', filename)\n",
        "    if match:\n",
        "        return match.group(1)\n",
        "\n",
        "    # If no match found, return the filename without extension\n",
        "    return os.path.splitext(os.path.basename(filename))[0]\n",
        "\n",
        "def parse_sequence_number(filename):\n",
        "    \"\"\"Parse the sequence number from the filename.\"\"\"\n",
        "    match = re.search(r'dldesign_(\\d+)_', filename)\n",
        "    if match:\n",
        "        return match.group(1)\n",
        "\n",
        "    # If no match found, return an empty string\n",
        "    return \"\"\n",
        "\n",
        "def convert_pdb_to_fasta(pdb_dir, chain_id):\n",
        "    \"\"\"Convert all PDB files in the directory to FASTA format.\"\"\"\n",
        "    # Verify the directory exists\n",
        "    if not os.path.isdir(pdb_dir):\n",
        "        print(f\"Error: Directory not found: {pdb_dir}\")\n",
        "        return False\n",
        "\n",
        "    # Get all PDB files in the directory\n",
        "    pdb_files = glob.glob(os.path.join(pdb_dir, \"*.pdb\"))\n",
        "\n",
        "    if not pdb_files:\n",
        "        print(f\"No PDB files found in {pdb_dir}\")\n",
        "        return False\n",
        "\n",
        "    print(f\"Found {len(pdb_files)} PDB files in {pdb_dir}\")\n",
        "    print(f\"Extracting sequences from chain {chain_id}...\")\n",
        "\n",
        "    # Create a list to store all FASTA entries\n",
        "    all_fasta_entries = []\n",
        "\n",
        "    processed_count = 0\n",
        "    for pdb_file in pdb_files:\n",
        "        # Extract filename from path\n",
        "        filename = os.path.basename(pdb_file)\n",
        "\n",
        "        # Extract design and sequence numbers\n",
        "        design_num = parse_design_number(filename)\n",
        "        seq_num = parse_sequence_number(filename)\n",
        "\n",
        "        # Generate FASTA header\n",
        "        if seq_num:\n",
        "            header = f\">{design_num}_{seq_num}\"\n",
        "        else:\n",
        "            header = f\">{design_num}\"\n",
        "\n",
        "        # Extract sequence\n",
        "        sequence = extract_sequence_from_pdb(pdb_file, chain_id)\n",
        "\n",
        "        if not sequence:\n",
        "            print(f\"Warning: No sequence found for chain {chain_id} in {filename}\")\n",
        "            continue\n",
        "\n",
        "        # Format the FASTA entry\n",
        "        fasta_entry = header + \"\\n\"\n",
        "        for i in range(0, len(sequence), 60):\n",
        "            fasta_entry += sequence[i:i+60] + \"\\n\"\n",
        "\n",
        "        # Add to the list of all entries\n",
        "        all_fasta_entries.append(fasta_entry)\n",
        "\n",
        "        # Write to individual FASTA file\n",
        "        output_file = os.path.join(pdb_dir, f\"{design_num}_{seq_num}.txt\")\n",
        "        with open(output_file, 'w') as f:\n",
        "            f.write(fasta_entry)\n",
        "\n",
        "        print(f\"Processed {filename} -> {os.path.basename(output_file)}\")\n",
        "        processed_count += 1\n",
        "\n",
        "    # Write all sequences to a single file\n",
        "    if processed_count > 0:\n",
        "        all_sequences_file = os.path.join(pdb_dir, \"all_sequences.txt\")\n",
        "        with open(all_sequences_file, 'w') as f:\n",
        "            f.write(\"\".join(all_fasta_entries))\n",
        "        print(f\"\\nCreated combined FASTA file: {all_sequences_file}\")\n",
        "\n",
        "    print(f\"\\nProcessed {processed_count} PDB files.\")\n",
        "    print(f\"FASTA files have been saved to {pdb_dir}\")\n",
        "    return True\n",
        "\n",
        "# Main execution\n",
        "print(f\"\\nPDB Directory: {PDB_DIRECTORY}\")\n",
        "print(f\"Chain ID: {CHAIN_ID}\")\n",
        "\n",
        "# Ask user if they want to change the default settings\n",
        "change_settings = input(\"Do you want to change these settings? (yes/no): \").lower().strip()\n",
        "\n",
        "if change_settings in [\"yes\", \"y\"]:\n",
        "    # Get directory path\n",
        "    new_dir = input(f\"Enter PDB directory path (current: {PDB_DIRECTORY}): \").strip()\n",
        "    if new_dir:\n",
        "        PDB_DIRECTORY = new_dir\n",
        "\n",
        "    # Get chain ID\n",
        "    new_chain = input(f\"Enter chain ID to extract (current: {CHAIN_ID}): \").strip()\n",
        "    if new_chain:\n",
        "        CHAIN_ID = new_chain\n",
        "\n",
        "# Run the conversion\n",
        "print(f\"\\nProcessing PDB files in {PDB_DIRECTORY}, extracting chain {CHAIN_ID}...\")\n",
        "success = convert_pdb_to_fasta(PDB_DIRECTORY, CHAIN_ID)\n",
        "\n",
        "if success:\n",
        "    print(\"\\nProcess completed successfully!\")\n",
        "else:\n",
        "    print(\"\\nFailed to process PDB files. Please check the directory path and try again.\")"
      ]
    }
  ]
}