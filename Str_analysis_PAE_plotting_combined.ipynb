{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1xwzBiaPb6Suf6xJYAmuPaisvAywiDgMB",
      "authorship_tag": "ABX9TyNwlBI7nQekzWP9+EoOZAqT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eoinleen/protein-design-final-dir/blob/main/Str_analysis_PAE_plotting_combined.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fi7ekQJPGinh",
        "outputId": "b5bf6d84-13c5-46e1-81cb-f55e342d8bf7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/270.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.2/270.1 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m270.1/270.1 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m472.8/472.8 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.9/79.9 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m165.1/165.1 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "RFdiffusion Structure Analysis and Visualization Tool\n",
        "==================================================\n",
        "\n",
        "About\n",
        "-----\n",
        "This script combines RFdiffusion pathway structure analysis with AF2 score visualization\n",
        "into a single automated pipeline. It processes PDB structures and generates publication-ready\n",
        "visualizations of structure-function relationships.\n",
        "\n",
        "Performance Note\n",
        "--------------\n",
        "Processing speed is approximately 2 seconds per structure due to comprehensive structural analysis.\n",
        "\n",
        "What Does It Do?\n",
        "--------------\n",
        "1. Analyzes PDB files from RFdiffusion-MPNN-AF2 pipeline\n",
        "2. Calculates key structural parameters:\n",
        "   - Buried surface area\n",
        "   - Hydrogen bonds\n",
        "   - Hydrophobic contacts\n",
        "   - Salt bridges\n",
        "3. Combines structural data with AF2 scores\n",
        "4. Generates publication-ready plots in PowerPoint format including:\n",
        "   - Structure-function correlation plots\n",
        "   - Comprehensive iPAE score visualization\n",
        "\n",
        "Credits\n",
        "-------\n",
        "Original Analysis Code: Dr. Eoin Leen, University of Leeds\n",
        "Visualization Components: Claude AI\n",
        "Integration & Optimization: Claude AI & User\n",
        "Version: 1.0 (2025)\n",
        "\"\"\"\n",
        "\n",
        "# Install required packages\n",
        "!pip install -q biopython pandas freesasa numpy matplotlib seaborn python-pptx plotly kaleido\n",
        "\n",
        "# Import required libraries\n",
        "import os\n",
        "import sys\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import files, drive\n",
        "from pathlib import Path\n",
        "from typing import Dict, List, Optional, Tuple, Any\n",
        "from Bio import PDB\n",
        "from Bio.PDB.PDBIO import PDBIO\n",
        "from Bio.PDB.Polypeptide import is_aa\n",
        "from Bio.PDB.Structure import Structure\n",
        "import freesasa\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "from pptx import Presentation\n",
        "from pptx.util import Inches, Cm\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "class StructureValidationError(Exception):\n",
        "    pass\n",
        "\n",
        "def validate_pdb_file(file_path: str) -> bool:\n",
        "    if not os.path.exists(file_path):\n",
        "        raise FileNotFoundError(f\"PDB file not found: {file_path}\")\n",
        "    try:\n",
        "        with open(file_path, 'r') as f:\n",
        "            first_line = f.readline()\n",
        "            if not any(marker in first_line for marker in ['HEADER', 'ATOM', 'MODEL']):\n",
        "                raise StructureValidationError(f\"Invalid PDB: {file_path}\")\n",
        "    except UnicodeDecodeError:\n",
        "        raise StructureValidationError(f\"Not a valid text file: {file_path}\")\n",
        "    return True\n",
        "\n",
        "def safe_structure_load(parser: PDB.PDBParser, file_path: str) -> Optional[Structure]:\n",
        "    try:\n",
        "        validate_pdb_file(file_path)\n",
        "        structure = parser.get_structure('protein', file_path)\n",
        "        if not list(structure.get_models()):\n",
        "            raise StructureValidationError(\"No models\")\n",
        "        if not list(list(structure.get_models())[0].get_chains()):\n",
        "            raise StructureValidationError(\"No chains\")\n",
        "        return structure\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading {file_path}: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "def calculate_buried_surface_area(pdb_file: str) -> Tuple[Optional[float], Optional[Dict[str, float]]]:\n",
        "    parser = PDB.PDBParser(QUIET=True)\n",
        "    structure = safe_structure_load(parser, pdb_file)\n",
        "    if not structure:\n",
        "        return None, None\n",
        "    try:\n",
        "        chains = list(structure.get_chains())\n",
        "        if len(chains) < 2:\n",
        "            print(f\"Warning: {pdb_file} has fewer than 2 chains\")\n",
        "            return None, None\n",
        "\n",
        "        combined_structure = freesasa.Structure(pdb_file)\n",
        "        result = freesasa.calc(combined_structure)\n",
        "        total_area = result.totalArea()\n",
        "\n",
        "        chain_areas = {}\n",
        "        io = PDBIO()\n",
        "        temp_files = []\n",
        "\n",
        "        for chain in chains:\n",
        "            new_structure = PDB.Structure.Structure('temp')\n",
        "            new_model = PDB.Model.Model(0)\n",
        "            new_structure.add(new_model)\n",
        "            new_model.add(chain.copy())\n",
        "\n",
        "            temp_file = f\"temp_chain_{chain.id}.pdb\"\n",
        "            temp_files.append(temp_file)\n",
        "\n",
        "            io.set_structure(new_structure)\n",
        "            io.save(temp_file)\n",
        "\n",
        "            chain_structure = freesasa.Structure(temp_file)\n",
        "            chain_result = freesasa.calc(chain_structure)\n",
        "            chain_areas[chain.id] = chain_result.totalArea()\n",
        "\n",
        "        for temp_file in temp_files:\n",
        "            if os.path.exists(temp_file):\n",
        "                os.remove(temp_file)\n",
        "\n",
        "        total_individual_area = sum(chain_areas.values())\n",
        "        buried_surface_area = abs(total_individual_area - total_area) / 2\n",
        "        return buried_surface_area, chain_areas\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error calculating BSA for {pdb_file}: {str(e)}\")\n",
        "        return None, None\n",
        "\n",
        "def calculate_hydrogen_bonds(structure: Structure) -> int:\n",
        "    try:\n",
        "        h_bonds = 0\n",
        "        for chain1 in structure.get_chains():\n",
        "            for chain2 in structure.get_chains():\n",
        "                if chain1.id >= chain2.id:\n",
        "                    continue\n",
        "                for res1 in chain1.get_residues():\n",
        "                    if not is_aa(res1):\n",
        "                        continue\n",
        "                    for res2 in chain2.get_residues():\n",
        "                        if not is_aa(res2):\n",
        "                            continue\n",
        "                        if 'O' in res1 and 'N' in res2:\n",
        "                            distance = res1['O'] - res2['N']\n",
        "                            if distance < 3.5:\n",
        "                                h_bonds += 1\n",
        "        return h_bonds\n",
        "    except Exception as e:\n",
        "        print(f\"Error calculating H-bonds: {str(e)}\")\n",
        "        return 0\n",
        "\n",
        "def calculate_hydrophobic_contacts(structure: Structure) -> int:\n",
        "    try:\n",
        "        hydrophobic_residues = {'ALA', 'VAL', 'LEU', 'ILE', 'MET', 'PHE', 'TRP', 'PRO'}\n",
        "        contacts = 0\n",
        "        for chain1 in structure.get_chains():\n",
        "            for chain2 in structure.get_chains():\n",
        "                if chain1.id >= chain2.id:\n",
        "                    continue\n",
        "                for res1 in chain1.get_residues():\n",
        "                    if not is_aa(res1) or res1.get_resname() not in hydrophobic_residues:\n",
        "                        continue\n",
        "                    for res2 in chain2.get_residues():\n",
        "                        if not is_aa(res2) or res2.get_resname() not in hydrophobic_residues:\n",
        "                            continue\n",
        "                        min_distance = float('inf')\n",
        "                        for atom1 in res1.get_atoms():\n",
        "                            for atom2 in res2.get_atoms():\n",
        "                                distance = atom1 - atom2\n",
        "                                min_distance = min(min_distance, distance)\n",
        "                        if min_distance < 5.0:\n",
        "                            contacts += 1\n",
        "        return contacts\n",
        "    except Exception as e:\n",
        "        print(f\"Error calculating hydrophobic contacts: {str(e)}\")\n",
        "        return 0\n",
        "\n",
        "def calculate_salt_bridges(structure: Structure) -> int:\n",
        "    try:\n",
        "        acidic = {'ASP', 'GLU'}\n",
        "        basic = {'LYS', 'ARG', 'HIS'}\n",
        "        salt_bridges = 0\n",
        "        for chain1 in structure.get_chains():\n",
        "            for chain2 in structure.get_chains():\n",
        "                if chain1.id >= chain2.id:\n",
        "                    continue\n",
        "                for res1 in chain1.get_residues():\n",
        "                    if not is_aa(res1):\n",
        "                        continue\n",
        "                    res1_name = res1.get_resname()\n",
        "                    for res2 in chain2.get_residues():\n",
        "                        if not is_aa(res2):\n",
        "                            continue\n",
        "                        res2_name = res2.get_resname()\n",
        "                        if ((res1_name in acidic and res2_name in basic) or\n",
        "                            (res1_name in basic and res2_name in acidic)):\n",
        "                            min_distance = float('inf')\n",
        "                            for atom1 in res1.get_atoms():\n",
        "                                for atom2 in res2.get_atoms():\n",
        "                                    distance = atom1 - atom2\n",
        "                                    min_distance = min(min_distance, distance)\n",
        "                            if min_distance < 4.0:\n",
        "                                salt_bridges += 1\n",
        "        return salt_bridges\n",
        "    except Exception as e:\n",
        "        print(f\"Error calculating salt bridges: {str(e)}\")\n",
        "        return 0\n",
        "\n",
        "def save_results_as_df(results: List[Dict[str, Any]], pdb_directory: str) -> pd.DataFrame:\n",
        "    analysis_data = []\n",
        "    for result in results:\n",
        "        filename = result['file_name'].replace('.pdb', '')\n",
        "        try:\n",
        "            design_num = int(filename.split('design')[1].split('_')[0])\n",
        "            variant_num = int(filename.split('_n')[1])\n",
        "            analysis_data.append({\n",
        "                'design': design_num,\n",
        "                'n': variant_num,\n",
        "                'buried_surface_area': result['buried_surface_area'] if result['buried_surface_area'] else 0,\n",
        "                'hydrogen_bonds': result['hydrogen_bonds'],\n",
        "                'hydrophobic_contacts': result['hydrophobic_contacts'],\n",
        "                'salt_bridges': result['salt_bridges']\n",
        "            })\n",
        "        except Exception as e:\n",
        "            print(f\"Error parsing filename {filename}: {str(e)}\")\n",
        "            continue\n",
        "\n",
        "    df = pd.DataFrame(analysis_data)\n",
        "    df = df.sort_values(['design', 'n']).reset_index(drop=True)\n",
        "    output_file = os.path.join(pdb_directory, \"structure_analysis.csv\")\n",
        "    df.to_csv(output_file, index=False)\n",
        "    print(f\"Saved structure analysis to {output_file}\")\n",
        "    return df\n",
        "\n",
        "def merge_with_af2_scores(structure_df: pd.DataFrame, af2_scores_file: str) -> pd.DataFrame:\n",
        "    af2_df = pd.read_csv(af2_scores_file)\n",
        "    merged_df = pd.merge(af2_df, structure_df, on=['design', 'n'], how='left')\n",
        "    merged_df = merged_df.sort_values(['design', 'n']).reset_index(drop=True)\n",
        "    return merged_df\n",
        "\n",
        "def create_pptx_plots(df: pd.DataFrame, output_dir: str):\n",
        "    prs = Presentation()\n",
        "    prs.slide_width = Cm(21)\n",
        "    prs.slide_height = Cm(29.7)\n",
        "\n",
        "    # First slide - correlation plots\n",
        "    slide1 = prs.slides.add_slide(prs.slide_layouts[5])\n",
        "\n",
        "    fig, axes = plt.subplots(3, 2, figsize=(8.27, 11.69))\n",
        "    axes = axes.flatten()\n",
        "\n",
        "    y_vars = ['i_ptm', 'rmsd', 'buried_surface_area',\n",
        "              'hydrogen_bonds', 'hydrophobic_contacts', 'salt_bridges']\n",
        "    titles = ['iPTM', 'RMSD (Å)', 'Buried Surface Area (Å²)',\n",
        "             '# of Hydrogen Bonds', '# of Hydrophobic Contacts', '# of Salt Bridges']\n",
        "\n",
        "    for ax, y_var, title in zip(axes, y_vars, titles):\n",
        "        sns.scatterplot(data=df, x='i_pae', y=y_var, ax=ax, color='black', marker='x', s=16)\n",
        "        ax.set_xlabel('i_PAE')\n",
        "        ax.set_ylabel(title)\n",
        "        ax.set_title(title)\n",
        "        ax.set_facecolor('white')\n",
        "\n",
        "    fig.patch.set_facecolor('white')\n",
        "    plt.tight_layout()\n",
        "\n",
        "    temp_img1 = os.path.join(output_dir, 'temp_plots1.png')\n",
        "    plt.savefig(temp_img1, bbox_inches='tight', dpi=300, facecolor='white')\n",
        "    plt.close()\n",
        "\n",
        "    left = Cm(2)\n",
        "    top = Cm(2)\n",
        "    slide1.shapes.add_picture(temp_img1, left, top)\n",
        "\n",
        "    # Second slide - iPAE visualization\n",
        "    slide2 = prs.slides.add_slide(prs.slide_layouts[5])\n",
        "\n",
        "    # Create iPAE visualization\n",
        "    fig = make_subplots(\n",
        "        rows=4,\n",
        "        cols=1,\n",
        "        vertical_spacing=0.08,\n",
        "        subplot_titles=[f\"Designs {i*8}-{(i+1)*8-1}\" for i in range(4)]\n",
        "    )\n",
        "\n",
        "    rows_per_subplot = 512  # 8 designs × 64 sequences = 512 rows per subplot\n",
        "    colors = ['black', 'red']\n",
        "\n",
        "    for i in range(4):\n",
        "        start_idx = i * rows_per_subplot\n",
        "        end_idx = start_idx + rows_per_subplot\n",
        "        chunk = df.iloc[start_idx:end_idx].copy()\n",
        "\n",
        "        for design_num in chunk['design'].unique():\n",
        "            mask = chunk['design'] == design_num\n",
        "            color = colors[design_num % 2]\n",
        "\n",
        "            fig.add_trace(\n",
        "                go.Bar(\n",
        "                    x=chunk[mask].index,\n",
        "                    y=chunk[mask]['i_pae'],\n",
        "                    showlegend=False,\n",
        "                    marker_color=color,\n",
        "                    width=1,\n",
        "                ),\n",
        "                row=i+1,\n",
        "                col=1\n",
        "            )\n",
        "\n",
        "        fig.update_yaxes(\n",
        "            range=[0, 30],\n",
        "            title_text='iPAE' if i == 1 else None,\n",
        "            row=i+1,\n",
        "            col=1\n",
        "        )\n",
        "\n",
        "        design_numbers = sorted(chunk['design'].unique())\n",
        "        fig.update_xaxes(\n",
        "            tickmode='array',\n",
        "            ticktext=design_numbers,\n",
        "            tickvals=[start_idx + (j*64) + 32 for j in range(len(design_numbers))],\n",
        "            row=i+1,\n",
        "            col=1,\n",
        "            title_text='Design Number' if i == 3 else None\n",
        "        )\n",
        "\n",
        "    fig.update_layout(\n",
        "        title='iPAE Scores by Design Number and Sequence (Scale: 0-30)',\n",
        "        height=1000,\n",
        "        width=1200,\n",
        "        showlegend=False,\n",
        "        margin=dict(t=50, b=50, r=150, l=50),\n",
        "        paper_bgcolor='white',\n",
        "        plot_bgcolor='white'\n",
        "    )\n",
        "\n",
        "    temp_img2 = os.path.join(output_dir, 'temp_plots2.png')\n",
        "    fig.write_image(temp_img2)\n",
        "\n",
        "    left = Cm(1)\n",
        "    top = Cm(1)\n",
        "    slide2.shapes.add_picture(temp_img2, left, top)\n",
        "\n",
        "    # Save PowerPoint and clean up temporary files\n",
        "    pptx_path = os.path.join(output_dir, 'protein_analysis_plots.pptx')\n",
        "    prs.save(pptx_path)\n",
        "    os.remove(temp_img1)\n",
        "    os.remove(temp_img2)\n",
        "    print(f\"Saved PowerPoint to {pptx_path}\")\n",
        "\n",
        "def process_multiple_pdb_files(pdb_directory: str, af2_scores_file: str = None) -> pd.DataFrame:\n",
        "    if not os.path.exists(pdb_directory):\n",
        "        raise FileNotFoundError(f\"Directory not found: {pdb_directory}\")\n",
        "\n",
        "    results = []\n",
        "    parser = PDB.PDBParser(QUIET=True)\n",
        "    pdb_files = [f for f in os.listdir(pdb_directory) if f.endswith('.pdb')]\n",
        "\n",
        "    if not pdb_files:\n",
        "        print(f\"No PDB files found in {pdb_directory}\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    print(f\"Processing {len(pdb_files)} PDB files...\")\n",
        "    for file_name in pdb_files:\n",
        "        pdb_file = os.path.join(pdb_directory, file_name)\n",
        "        print(f\"Processing {file_name}...\")\n",
        "\n",
        "        structure = safe_structure_load(parser, pdb_file)\n",
        "        if not structure:\n",
        "            continue\n",
        "\n",
        "        buried_surface_area, chain_areas = calculate_buried_surface_area(pdb_file)\n",
        "        h_bonds = calculate_hydrogen_bonds(structure)\n",
        "        hydrophobic = calculate_hydrophobic_contacts(structure)\n",
        "        salt_bridges = calculate_salt_bridges(structure)\n",
        "\n",
        "        results.append({\n",
        "            'file_name': file_name,\n",
        "            'buried_surface_area': buried_surface_area,\n",
        "            'hydrogen_bonds': h_bonds,\n",
        "            'hydrophobic_contacts': hydrophobic,\n",
        "            'salt_bridges': salt_bridges,\n",
        "            'chain_areas': chain_areas\n",
        "        })\n",
        "\n",
        "    structure_df = save_results_as_df(results, pdb_directory)\n",
        "\n",
        "    if af2_scores_file and os.path.exists(af2_scores_file):\n",
        "        print(f\"Merging with AF2 scores from {af2_scores_file}\")\n",
        "        final_df = merge_with_af2_scores(structure_df, af2_scores_file)\n",
        "        combined_file = os.path.join(pdb_directory, \"combined_analysis.csv\")\n",
        "        final_df.to_csv(combined_file, index=False)\n",
        "        print(f\"Saved combined results to {combined_file}\")\n",
        "        create_pptx_plots(final_df, pdb_directory)\n",
        "        return final_df\n",
        "    return structure_df\n",
        "\n",
        "# Main execution\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "pdb_directory = '/content/drive/MyDrive/PDB-files/202501xx/3NOB-70-110-all_pdb'  # Change this path\n",
        "af2_scores_path = os.path.join(pdb_directory, 'af2_scores.csv')\n",
        "\n",
        "if not os.path.exists(af2_scores_path):\n",
        "    af2_scores_path = None\n",
        "    print(\"No AF2 scores file found - will generate structure analysis only\")\n",
        "\n",
        "print(\"Starting analysis...\")\n",
        "print(f\"Processing PDB files from: {pdb_directory}\")\n",
        "\n",
        "results_df = process_multiple_pdb_files(pdb_directory, af2_scores_path)"
      ]
    }
  ]
}